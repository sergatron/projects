{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar Array Cost Prediction ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error, make_scorer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, f_regression\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor \n",
    "\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OrdinalEncoder??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format float in pandas\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.options.display.max_columns = 30\n",
    "pd.options.display.max_rows = 50\n",
    "pd.options.display.width = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "rcParams['axes.labelsize'] = 'x-large'\n",
    "rcParams['axes.edgecolor'] = 'black'\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['axes.titlesize'] = 'x-large'\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['axes.xmargin'] = 0.02\n",
    "rcParams['axes.ymargin'] = 0.02\n",
    "            \n",
    "rcParams['axes.grid'] = True\n",
    "rcParams['grid.linestyle'] = ':'\n",
    "rcParams['grid.alpha'] = 0.2\n",
    "rcParams['grid.color'] = 'black'\n",
    "          \n",
    "rcParams['figure.titlesize'] = 'x-large'\n",
    "rcParams['figure.edgecolor']= 'black'\n",
    "rcParams['figure.facecolor'] = 'white'\n",
    "rcParams['figure.figsize'] = [12, 8]\n",
    "\n",
    "rcParams['ytick.labelsize'] = 'large'\n",
    "rcParams['xtick.labelsize'] = 'large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\smouz\\\\Google Drive\\\\jupyter_notebook\\\\projects\\\\solar_array'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 612172 entries, 0 to 612171\n",
      "Data columns (total 35 columns):\n",
      "date_installed                 612172 non-null object\n",
      "state                          612172 non-null object\n",
      "incentive_prog_names           459717 non-null object\n",
      "size_kw                        612172 non-null float64\n",
      "zipcode                        612172 non-null int64\n",
      "install_type                   612172 non-null object\n",
      "installer                      401915 non-null object\n",
      "cost_per_watt                  612168 non-null float64\n",
      "cost                           612172 non-null float64\n",
      "city                           461178 non-null object\n",
      "utility_clean                  457662 non-null object\n",
      "tech_1                         358820 non-null object\n",
      "model1_clean                   358820 non-null object\n",
      "county                         608230 non-null object\n",
      "annual_pv_prod                 612172 non-null float64\n",
      "annual_insolation              612167 non-null float64\n",
      "rebate                         302666 non-null float64\n",
      "sales_tax_cost                 283211 non-null float64\n",
      "tilt1                          307962 non-null float64\n",
      "tracking_type                  328959 non-null object\n",
      "azimuth1                       289230 non-null float64\n",
      "reported_annual_energy_prod    166494 non-null float64\n",
      "3rdparty                       612172 non-null int64\n",
      "incentive_count                607536 non-null float64\n",
      "total_cost                     612172 non-null float64\n",
      "area_est                       612167 non-null float64\n",
      "power_density                  612167 non-null float64\n",
      "rebate_cost_ratio              302666 non-null float64\n",
      "sales_tax_percent              283211 non-null float64\n",
      "size_catg                      612172 non-null object\n",
      "month                          612172 non-null int64\n",
      "day                            612172 non-null int64\n",
      "year                           612172 non-null int64\n",
      "cost_mo_agg_med                612172 non-null float64\n",
      "month_install_cnt              612172 non-null int64\n",
      "dtypes: float64(17), int64(6), object(12)\n",
      "memory usage: 163.5+ MB\n"
     ]
    }
   ],
   "source": [
    "pv_df = pd.read_csv('pv_df_clean_2.csv', low_memory=False)\n",
    "pv_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_n_reset(df):\n",
    "    '''\n",
    "    axis = {0: rows, 1: columns}\n",
    "    Drop row if all values are missing in that column,\n",
    "    Drop row if all values are missing in that row, drop duplicates\n",
    "    Reset index, drop original index\n",
    "    '''\n",
    "    df = df.dropna(axis=1, how='all') \n",
    "    df = df.dropna(axis=0, how='all').drop_duplicates()\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing rows where cost is missing\n",
    "# pv_df[pv_df['cost'].isnull().values] = np.nan\n",
    "pv_df = drop_n_reset(pv_df)\n",
    "# pv_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Convert to datetime\n",
    "# =============================================================================\n",
    "date_time = '%Y-%m-%d'\n",
    "datetime = pd.to_datetime(pv_df['date_installed'], format=date_time)\n",
    "clean_pv = pv_df.set_index(datetime).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pv = clean_pv['1998':'2017']\n",
    "# clean_pv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_pv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "### Combine Technology Type\n",
    "\n",
    "Combine features which appear infrequently into a single group called '*other*'. This will reduce the size of the sparse matrix that will be created when categorical variables are encoded. Additionally, new features can be created from existing numeric and categoric features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts_of(array, df=clean_pv, count=True):\n",
    "    if count:\n",
    "        return df[array].value_counts()\n",
    "    return df[array].value_counts() / np.count_nonzero(df[array].notnull()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poly             58.6339\n",
       "mono             38.3376\n",
       "crystalline       1.5807\n",
       "mono + a-si       1.0833\n",
       "cigs              0.1633\n",
       "cdte              0.1243\n",
       "a-si              0.0399\n",
       "a-si + micro-c    0.0139\n",
       "thin film         0.0123\n",
       "multiple          0.0095\n",
       "cis               0.0014\n",
       "Name: tech_1, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion of technology types\n",
    "tech_counts = clean_pv['tech_1'].value_counts() / np.count_nonzero(clean_pv['tech_1'].notnull()) * 100\n",
    "tech_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['crystalline', 'mono + a-si', 'cigs', 'cdte', 'a-si', 'a-si + micro-c', 'thin film',\n",
       "       'multiple', 'cis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine technology types which appear infrequently into a single group called 'other'\n",
    "tech_counts[tech_counts < 38].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = clean_pv['tech_1'].isin(tech_counts[tech_counts < 38].index)\n",
    "clean_pv['tech_1'][mask] = 'others'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Variables: *tech_1*\n",
    "Reduce the amount of variables in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poly      210390\n",
       "mono      137563\n",
       "others     10867\n",
       "Name: tech_1, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_pv['tech_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tech_1\n",
       "mono     29433.8384\n",
       "others   32187.3851\n",
       "poly     28387.4800\n",
       "Name: cost, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_pv.groupby('tech_1')['cost'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(feature, threshold, df=clean_pv, new_tag='others'):\n",
    "    state_count = counts_of(feature)\n",
    "    mask = clean_pv[feature].isin(state_count[state_count < threshold].index)\n",
    "    clean_pv[feature][mask] = new_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Variables: *tracking_type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed          327876\n",
       "single-axis       467\n",
       "dual-axis         363\n",
       "mixed             253\n",
       "Name: tracking_type, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_of('tracking_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed       327876\n",
       "has_axis      1083\n",
       "Name: tracking_type, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_features('tracking_type', 500, new_tag='has_axis')\n",
    "counts_of('tracking_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_pv.select_dtypes(include='object').sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RobustScaler().fit_transform(state['annual_insolation'].dropna())\n",
    "\n",
    "# state = clean_pv[clean_pv.state == 'ca']\n",
    "# t = 1\n",
    "# sns.distplot(clean_pv['annual_insolation'].dropna()**(t))\n",
    "# sns.distplot(clean_pv['cost'].dropna()**(t))\n",
    "# sns.distplot(clean_pv['size_kw'].dropna()**(t))\n",
    "\n",
    "# sns.distplot(clean_pv['cost'].dropna()**(t))\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 1/2\n",
    "# t=1\n",
    "# scaled_df = pd.DataFrame()\n",
    "# scaled_df['insolation_RB'] = np.arange(len(clean_pv))\n",
    "# scaler = StandardScaler()\n",
    "# pow_tx = PowerTransformer()\n",
    "# quant_tx = QuantileTransformer(n_quantiles=1000, output_distribution='normal')\n",
    "\n",
    "# def transform_variable(feature, df=clean_pv):\n",
    "#     power_transform = pow_tx.fit_transform((clean_pv[[feature]]).fillna(clean_pv[feature].mean()))\n",
    "#     standard_scaler = scaler.fit_transform((clean_pv[[feature]]**t).fillna(clean_pv[feature].mean()))\n",
    "#     quantile_transform = quant_tx.fit_transform((clean_pv[[feature]]).fillna(clean_pv[feature].mean()))\n",
    "#     return power_transform, standard_scaler, quantile_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(scaled_df['insolation'])\n",
    "# sns.distplot(scaled_df['cost'])\n",
    "# sns.distplot(scaled_df['size'])\n",
    "\n",
    "# power_tx, stand, qnt_tx = transform_variable(feature='cost')\n",
    "\n",
    "# sns.distplot(MinMaxScaler().fit_transform(stand))\n",
    "# sns.distplot(stand)\n",
    "# sns.distplot(power_tx)\n",
    "# sns.distplot(qnt_tx)\n",
    "# plt.legend(('power', 'square root', 'quantile'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.probplot(qnt_tx.ravel(), dist=\"norm\", plot=plt)\n",
    "# plt.show()\n",
    "\n",
    "# stats.probplot(qnt_tx.ravel(), dist=\"norm\", plot=plt)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_missing(df, threshold=50, drop=False):\n",
    "    \"\"\"\n",
    "    Calculate percent missing values in each column.\n",
    "    \n",
    "    Returns a series showing the proportion of missing vals in each column\n",
    "    \n",
    "    Drop columns which contain more than <threshold> missing values.\n",
    "    \"\"\"\n",
    "    ms = (np.sum(df.isnull()) / len(df)) * 100\n",
    "    if drop:\n",
    "        return df.drop(labels=ms[ms >= threshold].index, axis=1)     \n",
    "    else:\n",
    "        return ms.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_installed                 0.0000\n",
       "year                           0.0000\n",
       "day                            0.0000\n",
       "month                          0.0000\n",
       "size_catg                      0.0000\n",
       "total_cost                     0.0000\n",
       "3rdparty                       0.0000\n",
       "cost_mo_agg_med                0.0000\n",
       "annual_pv_prod                 0.0000\n",
       "month_install_cnt              0.0000\n",
       "state                          0.0000\n",
       "cost                           0.0000\n",
       "size_kw                        0.0000\n",
       "zipcode                        0.0000\n",
       "install_type                   0.0000\n",
       "cost_per_watt                  0.0007\n",
       "annual_insolation              0.0008\n",
       "power_density                  0.0008\n",
       "area_est                       0.0008\n",
       "county                         0.6432\n",
       "incentive_count                0.7566\n",
       "city                          24.6531\n",
       "incentive_prog_names          24.8917\n",
       "utility_clean                 25.2274\n",
       "installer                     34.3353\n",
       "model1_clean                  41.3762\n",
       "tech_1                        41.3762\n",
       "tracking_type                 46.2549\n",
       "tilt1                         49.6853\n",
       "rebate_cost_ratio             50.5506\n",
       "rebate                        50.5506\n",
       "azimuth1                      52.7458\n",
       "sales_tax_percent             53.7291\n",
       "sales_tax_cost                53.7291\n",
       "reported_annual_energy_prod   72.7983\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing(clean_pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# - December is cheaper apparently, but the difference between MIN and MAX doesn't seem significant enough\n",
    "#   for making predictions\n",
    "\n",
    "# (pv_dm['cost_mo_agg_med'] / pv_dm['month_install_cnt']).describe()\n",
    "# clean_pv.groupby('month')['cost'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tracking_type\n",
       "fixed      27700.0000\n",
       "has_axis   26705.2200\n",
       "Name: cost, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE:\n",
    "# - not a good predictor of cost\n",
    "clean_pv.groupby('tracking_type')['cost'].median()\n",
    "# pv_dm['tracking_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "743"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean_pv.groupby('zipcode')['cost'].median()\n",
    "clean_pv['county'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_dm = clean_pv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(pv_dm.columns.to_list()[:5])\n",
    "# pv_dm.values[:, 1][:5]\n",
    "\n",
    "list(pv_dm.columns).index('size_kw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, to_drop=['date_installed', 'total_cost', '3rdparty', 'incentive_prog_names', 'zipcode',\n",
    "                              'install_type', 'installer', 'city', 'utility_clean', 'model1_clean', 'tilt1',]):\n",
    "    try:\n",
    "        df = clean_pv.copy()\n",
    "        df['rebate_per_kwh'] = df['rebate'] / df['annual_pv_prod']\n",
    "        # drop missing values over 50%\n",
    "        df = percent_missing(df, 50, drop=True)\n",
    "        # drop features\n",
    "        df = df.drop(to_drop, axis=1)\n",
    "\n",
    "        # create new features\n",
    "        df['cost_per_area'] = df['cost'] / df['area_est']\n",
    "        df['cost_per_kwh'] = df['cost'] / df['annual_pv_prod']\n",
    "        \n",
    "        # adjust dtype\n",
    "        df['month'] = df['month'].astype('category')\n",
    "        df['day'] = df['day'].astype('category')\n",
    "        df['year'] = df['year'].astype('category')\n",
    "        \n",
    "        # FREQUENCIES\n",
    "        # month frequency\n",
    "        month_freq = df['month'].value_counts()/len(df)\n",
    "        df['month_freq'] = df['month'].map(month_freq)\n",
    "\n",
    "        # month frequency\n",
    "        county_freq = df['county'].value_counts()/len(df)\n",
    "        df['county_freq'] = df['county'].map(county_freq)\n",
    "        \n",
    "        # state frequency, scaled\n",
    "        state_freq = (df['state'].value_counts() / len(df))\n",
    "        state_fr_scaled = ((np.log(1/(state_freq))) * state_freq) *100\n",
    "        df['state_fr_scaled'] = df['state'].map(state_fr_scaled)\n",
    "        \n",
    "        # technology type\n",
    "        tech_freq = df['tech_1'].value_counts()/len(df)\n",
    "        df['tech_freq'] = df['tech_1'].map(tech_freq)\n",
    "                \n",
    "        # AGGREGATE\n",
    "        # monthly cost aggregate / monthly installation count\n",
    "        df['cost_per_install'] = df['cost_mo_agg_med']/df['month_install_cnt']\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Something went wrong')\n",
    "        print(e)\n",
    "        pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_dm = process_data(pv_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_fr_scaled = ((np.log(1/(state_freq))) * state_freq) *100\n",
    "# pv_dm['state_fr_scaled'] = pv_dm['state'].map(state_fr_scaled)\n",
    "# state_fr_scaled[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_freq = (pv_dm['state'].value_counts() / len(pv_dm))**(1/2)\n",
    "# state_freq[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df_train, df_test, target='cost'):\n",
    "    \"\"\"\n",
    "    Returns arrays of X, y train and test sets\n",
    "    Exclude additional features with param `drop_features` from predictors arrays\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        df_train:      training set\n",
    "        df_test:       testing set\n",
    "        target:        target variable\n",
    "        drop_features: drop additional features from df\n",
    "    \n",
    "    Returns:\n",
    "    -----------\n",
    "        X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train = df_train.drop(target, axis=1)\n",
    "    X_test = df_test.drop(target, axis=1)\n",
    "    y_train = df_train[[target]]\n",
    "    y_test = df_test[[target]]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "    \n",
    "def drop_features(df_train, df_test, drop):\n",
    "    df_train = df_train.drop(drop, axis=1)\n",
    "    df_test = df_test.drop(drop, axis=1)\n",
    "    return df_train, df_test\n",
    "\n",
    "def train_test_df(df, end_date, start_date, show_split=False):\n",
    "    \"\"\"\n",
    "    Split dataframe into Training and Testing set by dates.\n",
    "    \n",
    "    Training set will be past data, from start to `split_date`.\n",
    "    \n",
    "    Testing set will more future data, from `split_date` to end.\n",
    "    \n",
    "    The goal is to have about 80/20 split.\n",
    "    \"\"\"\n",
    "    train_set = df.loc[:end_date, :]\n",
    "    test_set = df.loc[start_date:, :]\n",
    "    if show_split:\n",
    "        # return split proportion of TRAIN, TEST\n",
    "        return len(train_set)/len(df), len(test_set)/len(df)\n",
    "    return train_set, test_set\n",
    "\n",
    "# select numeric dtype \n",
    "def get_numeric_data(df):\n",
    "    return df.select_dtypes(include=np.float64)\n",
    "\n",
    "# select categoric dtype \n",
    "def get_non_numeric_data(df):\n",
    "    return df.select_dtypes(exclude=np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical columns\n",
    "\n",
    "# train_set, test_set = train_test_df(pv_dm, '2015-05-31', '2015-06-01', show_split=False)\n",
    "# train_set.columns\n",
    "# get_non_numeric_data(train_set).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, test_set = train_test_df(pv_dm, '2015-05-31', '2015-06-01')\n",
    "\n",
    "# drop = ['state', 'size_catg', 'cost_per_watt', ]\n",
    "# train_set, test_set = drop_features(train_set, test_set, drop=drop)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_set,\n",
    "#                                                     test_set,\n",
    "#                                                     'cost'\n",
    "#                                                    )\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilinear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(model, X_train, y_train, X_test, y_test, y_pred):\n",
    "    print('Metrics:')\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  \n",
    "    print('Train set R^2 score:       ', model.score(X_train, y_train))\n",
    "    print('Test set R^2 score:        ', model.score(X_test, y_test))   \n",
    "    print('Mean absolute error:       ', mean_absolute_error(y_test, y_pred))\n",
    "    print('RMSE on test set:          ', rmse)\n",
    "    print('='*50)\n",
    "    \n",
    "def coeff_table(estimator, dropped = ['cost']):\n",
    "    print('Coefficients:')\n",
    "    coef_df = pd.DataFrame(estimator.coef_, columns=[train_set.drop(dropped, axis=1).columns]).transpose()\n",
    "    return coef_df[0].sort_values()\n",
    "\n",
    "def to_coeff_table(data, index):\n",
    "    print('Coefficients:')\n",
    "    return pd.Series(data, index).sort_values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColumnTransformer\n",
    "Combines transformer for two different types of features (different dtypes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pv_dm = process_data(clean_pv.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>size_kw</th>\n",
       "      <th>cost_per_watt</th>\n",
       "      <th>cost</th>\n",
       "      <th>tech_1</th>\n",
       "      <th>county</th>\n",
       "      <th>annual_pv_prod</th>\n",
       "      <th>annual_insolation</th>\n",
       "      <th>tracking_type</th>\n",
       "      <th>incentive_count</th>\n",
       "      <th>area_est</th>\n",
       "      <th>power_density</th>\n",
       "      <th>size_catg</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>cost_mo_agg_med</th>\n",
       "      <th>month_install_cnt</th>\n",
       "      <th>cost_per_area</th>\n",
       "      <th>cost_per_kwh</th>\n",
       "      <th>month_freq</th>\n",
       "      <th>county_freq</th>\n",
       "      <th>state_fr_scaled</th>\n",
       "      <th>tech_freq</th>\n",
       "      <th>cost_per_install</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_installed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-17</th>\n",
       "      <td>ca</td>\n",
       "      <td>5.2800</td>\n",
       "      <td>6540.0000</td>\n",
       "      <td>34556.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>8071.9908</td>\n",
       "      <td>2267.1043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0000</td>\n",
       "      <td>26.3740</td>\n",
       "      <td>0.2002</td>\n",
       "      <td>normal</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>2012</td>\n",
       "      <td>26268.0000</td>\n",
       "      <td>4771</td>\n",
       "      <td>1310.2316</td>\n",
       "      <td>4.2810</td>\n",
       "      <td>0.1121</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>31.3057</td>\n",
       "      <td>nan</td>\n",
       "      <td>5.5058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>ca</td>\n",
       "      <td>3.5840</td>\n",
       "      <td>6525.5804</td>\n",
       "      <td>23387.6800</td>\n",
       "      <td>poly</td>\n",
       "      <td>lake</td>\n",
       "      <td>5388.8223</td>\n",
       "      <td>1989.5119</td>\n",
       "      <td>fixed</td>\n",
       "      <td>55.0000</td>\n",
       "      <td>20.0638</td>\n",
       "      <td>0.1786</td>\n",
       "      <td>small</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>31655.1500</td>\n",
       "      <td>2690</td>\n",
       "      <td>1165.6645</td>\n",
       "      <td>4.3400</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>31.3057</td>\n",
       "      <td>0.3437</td>\n",
       "      <td>11.7677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-20</th>\n",
       "      <td>nj</td>\n",
       "      <td>6.4500</td>\n",
       "      <td>7450.0000</td>\n",
       "      <td>48053.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ocean</td>\n",
       "      <td>9860.6706</td>\n",
       "      <td>1811.1512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>40.3290</td>\n",
       "      <td>0.1599</td>\n",
       "      <td>large</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>2010</td>\n",
       "      <td>46334.0000</td>\n",
       "      <td>320</td>\n",
       "      <td>1191.5233</td>\n",
       "      <td>4.8732</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>4.5829</td>\n",
       "      <td>nan</td>\n",
       "      <td>144.7937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-25</th>\n",
       "      <td>ca</td>\n",
       "      <td>3.2250</td>\n",
       "      <td>5210.0000</td>\n",
       "      <td>16802.2500</td>\n",
       "      <td>poly</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>5026.4944</td>\n",
       "      <td>2046.6270</td>\n",
       "      <td>fixed</td>\n",
       "      <td>62.0000</td>\n",
       "      <td>18.1925</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>small</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>2012</td>\n",
       "      <td>27000.0000</td>\n",
       "      <td>4140</td>\n",
       "      <td>923.5804</td>\n",
       "      <td>3.3427</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>31.3057</td>\n",
       "      <td>0.3437</td>\n",
       "      <td>6.5217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-27</th>\n",
       "      <td>ca</td>\n",
       "      <td>1.8400</td>\n",
       "      <td>4608.1522</td>\n",
       "      <td>8479.0000</td>\n",
       "      <td>mono</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>2892.7498</td>\n",
       "      <td>2029.6276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0000</td>\n",
       "      <td>10.5575</td>\n",
       "      <td>0.1743</td>\n",
       "      <td>small</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>2012</td>\n",
       "      <td>26268.0000</td>\n",
       "      <td>4771</td>\n",
       "      <td>803.1264</td>\n",
       "      <td>2.9311</td>\n",
       "      <td>0.1121</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>31.3057</td>\n",
       "      <td>0.2247</td>\n",
       "      <td>5.5058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               state  size_kw  cost_per_watt       cost tech_1       county  annual_pv_prod  \\\n",
       "date_installed                                                                                \n",
       "2012-12-17        ca   5.2800      6540.0000 34556.0000    NaN  los angeles       8071.9908   \n",
       "2010-07-02        ca   3.5840      6525.5804 23387.6800   poly         lake       5388.8223   \n",
       "2010-07-20        nj   6.4500      7450.0000 48053.0000    NaN        ocean       9860.6706   \n",
       "2012-04-25        ca   3.2250      5210.0000 16802.2500   poly  los angeles       5026.4944   \n",
       "2012-12-27        ca   1.8400      4608.1522  8479.0000   mono  los angeles       2892.7498   \n",
       "\n",
       "                annual_insolation tracking_type  incentive_count  area_est  power_density  \\\n",
       "date_installed                                                                              \n",
       "2012-12-17              2267.1043           NaN          62.0000   26.3740         0.2002   \n",
       "2010-07-02              1989.5119         fixed          55.0000   20.0638         0.1786   \n",
       "2010-07-20              1811.1512           NaN          37.0000   40.3290         0.1599   \n",
       "2012-04-25              2046.6270         fixed          62.0000   18.1925         0.1773   \n",
       "2012-12-27              2029.6276           NaN          62.0000   10.5575         0.1743   \n",
       "\n",
       "               size_catg month day  year  cost_mo_agg_med  month_install_cnt  cost_per_area  \\\n",
       "date_installed                                                                                \n",
       "2012-12-17        normal    12  17  2012       26268.0000               4771      1310.2316   \n",
       "2010-07-02         small     7   2  2010       31655.1500               2690      1165.6645   \n",
       "2010-07-20         large     7  20  2010       46334.0000                320      1191.5233   \n",
       "2012-04-25         small     4  25  2012       27000.0000               4140       923.5804   \n",
       "2012-12-27         small    12  27  2012       26268.0000               4771       803.1264   \n",
       "\n",
       "                cost_per_kwh month_freq  county_freq  state_fr_scaled  tech_freq  cost_per_install  \n",
       "date_installed                                                                                      \n",
       "2012-12-17            4.2810     0.1121       0.0969          31.3057        nan            5.5058  \n",
       "2010-07-02            4.3400     0.0867       0.0014          31.3057     0.3437           11.7677  \n",
       "2010-07-20            4.8732     0.0867       0.0014           4.5829        nan          144.7937  \n",
       "2012-04-25            3.3427     0.0681       0.0969          31.3057     0.3437            6.5217  \n",
       "2012-12-27            2.9311     0.1121       0.0969          31.3057     0.2247            5.5058  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pv_dm.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                0.0000\n",
       "state_fr_scaled      0.0000\n",
       "month_freq           0.0000\n",
       "cost_per_kwh         0.0000\n",
       "month_install_cnt    0.0000\n",
       "cost_mo_agg_med      0.0000\n",
       "year                 0.0000\n",
       "day                  0.0000\n",
       "month                0.0000\n",
       "size_catg            0.0000\n",
       "annual_pv_prod       0.0000\n",
       "cost                 0.0000\n",
       "size_kw              0.0000\n",
       "cost_per_install     0.0000\n",
       "cost_per_watt        0.0007\n",
       "area_est             0.0008\n",
       "power_density        0.0008\n",
       "annual_insolation    0.0008\n",
       "cost_per_area        0.0008\n",
       "county               0.6432\n",
       "county_freq          0.6432\n",
       "incentive_count      0.7566\n",
       "tech_freq           41.3762\n",
       "tech_1              41.3762\n",
       "tracking_type       46.2549\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing(pv_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: feed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_features = ['state', 'size_catg', 'cost_per_watt', 'size_kw', 'annual_insolation','incentive_count']\n",
    "def feed_data(train_set, test_set, to_drop=['state', 'county', 'size_catg', \n",
    "                                            'day', \n",
    "                                            'year',\n",
    "                                            'month', \n",
    "                                            'cost_per_watt', \n",
    "                                            'size_kw',\n",
    "#                                             'annual_insolation', \n",
    "                                            'incentive_count',\n",
    "#                                             'annual_pv_prod',\n",
    "                                            'cost_per_install',\n",
    "                                            'month_install_cnt', 'cost_mo_agg_med',  \n",
    "#                                             'cost_per_area',\n",
    "#                                             'cost_per_kwh',\n",
    "                                            'month_freq',\n",
    "#                                             'county_freq', \n",
    "                                            'tech_freq',\n",
    "                                            'state_fr_scaled',\n",
    "                                            'tech_1', \n",
    "                                            'tracking_type',\n",
    "                                           ]): \n",
    "    \"\"\"\n",
    "    Drops additional features, and returns train/test split matrices, \n",
    "    and dataframe.\n",
    "    \n",
    "    How to use:\n",
    "    -----------\n",
    "    Unpack results into temporary variable, then assigned new variables \n",
    "    by indexing the temporary variable.\n",
    "        Example:\n",
    "        --------\n",
    "        temp = feed_data(train_set=train_, test_set=test_)\n",
    "        X_train, y_train, X_test, y_test = temp[0]\n",
    "        train_df = temp[1]\n",
    "        test_df = temp[2]\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Returns a tuple of train and test set split and additionally the \n",
    "    modified train and test dataframe.\n",
    "    `tuple(X_train, y_train, X_test, y_test), train, test`\n",
    "    \"\"\"\n",
    "    train, test = drop_features(df_train=train_set, df_test=test_set, drop=to_drop)\n",
    "    # returns: \n",
    "    #    X_train, y_train, X_test, y_test\n",
    "    return train_test_split(df_train=train,df_test=test, target='cost'), train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: build_pipeline()\n",
    "Regression Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(regressor, data=pv_dm, poly_degree=0, impute_strategy='mean', k_select=5, model_only=False, split_only=False, coef=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Reuse pipeline to test various regression algorithms.\n",
    "    \n",
    "    Process numeric and categoric features seperately.\n",
    "    \n",
    "    \"\"\"\n",
    "    train_, test_ = train_test_df(data, '2015-05-31', '2015-06-01')\n",
    "\n",
    "    # define train and test samples\n",
    "    # unpack into a temporary variable\n",
    "    temp = feed_data(train_set=train_, test_set=test_)\n",
    "    X_train, y_train, X_test, y_test = temp[0]\n",
    "    train_ = temp[1]\n",
    "    test_ = temp[2]\n",
    "    \n",
    "#     print('Features:', X_train.columns.to_list())\n",
    "    if split_only:\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    # Pipeline 1: preprocess numeric data\n",
    "    numeric_features = X_train.dtypes == 'float'\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', QuantileTransformer(output_distribution='normal')),      \n",
    "    ])  \n",
    "\n",
    "    # Pipeline 2: preprocess categorical features, if any\n",
    "    categorical_features = ~numeric_features\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ])\n",
    "\n",
    "    # COLUMN TRASNFORMER\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ], n_jobs=-1\n",
    "    )\n",
    "   \n",
    "    # MODEL PIPELINE\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('feature select', SelectKBest(f_regression, k=k_select)),\n",
    "        ('regressor', regressor(**kwargs)\n",
    "        )]\n",
    "    \n",
    "    model = Pipeline(steps)\n",
    "    \n",
    "    if poly_degree > 0:\n",
    "        # add step into pipeline when called for polynomials\n",
    "        print('Degree:', poly_degree)    \n",
    "        steps.insert(2,\n",
    "                     ('polynomial features', PolynomialFeatures(degree=poly_degree,\n",
    "                                                                include_bias=False))\n",
    "                    )\n",
    "        \n",
    "    if model_only:\n",
    "        return model\n",
    "\n",
    "#     pprint(model.named_steps['regressor'].get_params())\n",
    "    fit_start = time.time()\n",
    "    y_pred = model.fit(X_train, y_train.values.ravel()).predict(X_test)\n",
    "    print('Fit time:', time.time() - fit_start)\n",
    "    model_metrics(model, X_train, y_train, X_test, y_test, y_pred)\n",
    "    if coef:\n",
    "        pd.Series(X_train.columns, model.named_steps['regressor'].coef_)\n",
    "        return model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RidgeCV: Hyperparameters\n",
    "Higher alpha will penalize the coefficients more significantly and may lead to underfitting as the coefficients will become too small. Coefficients that are too small will underfit the data because the model will be too simple. An alpha of zero will result with the OLS loss function with zero regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n",
      "4.0\n",
      "4.5\n"
     ]
    }
   ],
   "source": [
    "# mse = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "mse_list = []\n",
    "\n",
    "# Start with a 1-4 range, and increment\n",
    "for i in np.arange(3,6):\n",
    "#     print(i, \"-\", i+3)\n",
    "    print(np.mean([1,i+3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(4,8):\n",
    "#     print('Trying range...', i, \"-\", i+3)\n",
    "#     alpha_space = np.logspace(i, i+3, 100)\n",
    "#     ridge_cv = build_pipeline(regressor=linear_model.RidgeCV, cv=3, scoring=mse, alphas=alpha_space, k_select=5)\n",
    "#     mse_list.append(ridge_cv.named_steps['regressor'].alpha_)\n",
    "# mse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_space = np.logspace(4.75, 4.9, 20)\n",
    "# ridge_cv = build_pipeline(regressor=linear_model.RidgeCV, cv=5, scoring=mse, alphas=alpha_space, k_select=5)\n",
    "# ridge_cv.named_steps['regressor'].alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 3.6657614707946777\n",
      "Metrics:\n",
      "Train set R^2 score:        0.9200972158306708\n",
      "Test set R^2 score:         0.9283698743271784\n",
      "Mean absolute error:        2348.030073264288\n",
      "RMSE on test set:           3203.8016707297456\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 0.1233, 0.4520, 0.0464, 15.85, 8697, 56234.13, 89449.71\n",
    "ridge = build_pipeline(regressor=linear_model.Ridge, alpha=89449.71, k_select='all', random_state=11, coef=True)\n",
    "# ridge.named_steps['regressor'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 4.349189043045044\n",
      "Metrics:\n",
      "Train set R^2 score:        0.9363092125449355\n",
      "Test set R^2 score:         0.9188513060068961\n",
      "Mean absolute error:        2250.3789823389243\n",
      "RMSE on test set:           3410.0326269382376\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.54886918e+03, 2.77395408e+02, 7.60102244e+03, 4.42314387e+03,\n",
       "       4.34144878e+03, 5.15525983e+00])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.1233, 0.4520, 0.0464, 15.85, 8697\n",
    "ridge = build_pipeline(regressor=linear_model.Ridge, alpha=8697, k_select=6, random_state=11)\n",
    "ridge.named_steps['regressor'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 3\n",
      "Fit time: 4.938671827316284\n",
      "Metrics:\n",
      "Train set R^2 score:        0.9980923369722384\n",
      "Test set R^2 score:         0.9966929945150184\n",
      "Mean absolute error:        400.26050262481533\n",
      "RMSE on test set:           688.3910647382899\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 0.1233, 0.4520, 0.0464, 8697, 129.1550\n",
    "ridge_poly = build_pipeline(regressor=linear_model.Ridge,\n",
    "                            poly_degree=3, \n",
    "                            alpha=129.1550, \n",
    "                            k_select=5, \n",
    "                            random_state=11, \n",
    "#                             data=pv_dm.sample(200000)\n",
    "                           )\n",
    "# ridge_poly.named_steps['regressor'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10468.164378512622\n",
      "589.4504279748796\n",
      "-1433.5404294349446\n",
      "1788.4769901222523\n"
     ]
    }
   ],
   "source": [
    "print(ridge_poly.named_steps['regressor'].coef_.max())\n",
    "print(ridge_poly.named_steps['regressor'].coef_.mean())\n",
    "print(ridge_poly.named_steps['regressor'].coef_.min())\n",
    "print(ridge_poly.named_steps['regressor'].coef_.std())\n",
    "# print(ridge_poly.named_steps['regressor'].coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['annual_pv_prod', 'annual_insolation', 'area_est', 'power_density', 'cost_per_area', 'cost_per_kwh', 'month_freq', 'county_freq']\n",
      "Degree: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 21.59193754196167\n",
      "Metrics:\n",
      "Train set R^2 score:        0.9923389079249749\n",
      "Test set R^2 score:         0.9871980027474586\n",
      "Mean absolute error:        818.1729921719539\n",
      "RMSE on test set:           1354.4302094674656\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "alpha_space = np.logspace(-1, 3, 100)\n",
    "lasso_cv = build_pipeline(regressor=linear_model.LassoCV, cv=5, alphas=alpha_space, n_jobs=-1, poly_degree=2, max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2782559402207124"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv.named_steps['regressor'].alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Poly: Degree=4, Long fit time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso_poly = build_pipeline(regressor=linear_model.Lasso, alpha=0.002, max_iter=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 58.488086462020874\n",
      "Metrics:\n",
      "Train set R^2 score:        0.9998533144067274\n",
      "Test set R^2 score:         0.9961932115025559\n",
      "Mean absolute error:        161.34679806130075\n",
      "RMSE on test set:           751.8106852852436\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# krr = build_pipeline(KernelRidge, alpha=0.021, kernel='rbf', degree=3, gamma=0.3, k_select=5, data=pv_dm.sample(25000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['annual_pv_prod', 'annual_insolation', 'area_est', 'power_density', 'cost_per_area', 'cost_per_kwh', 'state_fr_scaled', 'tech_freq']\n",
      "Fit time: 31.085333585739136\n",
      "Metrics:\n",
      "Train set R^2 score:        0.9999380800587073\n",
      "Test set R^2 score:         0.997741313720552\n",
      "Mean absolute error:        116.4557163587816\n",
      "RMSE on test set:           571.0792375552674\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# krr = build_pipeline(KernelRidge, alpha=0.0015, kernel='rbf', degree=3, gamma=0.3, k_select=5, data=pv_dm.sample(20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KernelRidge??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['annual_pv_prod', 'annual_insolation', 'area_est', 'power_density', 'cost_per_area', 'cost_per_kwh', 'state_fr_scaled', 'tech_freq']\n",
      "Degree: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 3.326791524887085\n",
      "Metrics:\n",
      "Train set R^2 score:        0.9919945162394004\n",
      "Test set R^2 score:         0.9856227906334356\n",
      "Mean absolute error:        812.9578702068746\n",
      "RMSE on test set:           1435.3409175340194\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# alpha: 0.1\n",
    "sgd = build_pipeline(regressor=linear_model.SGDRegressor, \n",
    "                     loss='squared_epsilon_insensitive', \n",
    "                     alpha=0.015,\n",
    "                     l1_ratio=0.15,\n",
    "                     epsilon=0.01,\n",
    "                     max_iter=10,\n",
    "                     poly_degree=2,\n",
    "                     k_select=5,\n",
    "                     random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha=129.1550, 89449.71\n",
    "# ridge_poly = build_pipeline(regressor=linear_model.Ridge, alpha=89449.71, k_select=5, random_state=11, data=pv_dm.sample(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 2\n",
      "Fit time: 0.8637833595275879\n",
      "Metrics:\n",
      "Train set R^2 score:        0.9926213822755944\n",
      "Test set R^2 score:         0.9878711061079226\n",
      "Mean absolute error:        804.9855815523558\n",
      "RMSE on test set:           1329.2000576943792\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:271: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 424.64457016479474\n",
      "Best params: {'regressor__alpha': 28.5714, 'polynomial features__degree': 5}\n"
     ]
    }
   ],
   "source": [
    "ridge_poly = build_pipeline(regressor=linear_model.Ridge, poly_degree=2, alpha=26, k_select=5, random_state=11, data=pv_dm.sample(200000))\n",
    "\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "ridge_params = {}\n",
    "# ridge_params['regressor__alpha'] = [26, 28.5714, 183]\n",
    "ridge_params['regressor__alpha'] = [28.5714]\n",
    "ridge_params['polynomial features__degree'] = [4,5]\n",
    "# ridge_params['feature select__k'] = [5]\n",
    "\n",
    "X_train, y_train, X_test, y_test = build_pipeline(linear_model.Ridge, split_only=True, data=pv_dm.sample(200000))\n",
    "search_cv = RandomizedSearchCV(\n",
    "    ridge_poly,\n",
    "    ridge_params,\n",
    "    scoring=mse,\n",
    "    n_jobs=-1,\n",
    "    cv=3,\n",
    "    random_state=11\n",
    ")\n",
    "search_cv.fit(X_train, y_train)\n",
    "print('Best RMSE:', np.sqrt((-1*(search_cv.best_score_))))\n",
    "print('Best params:', search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 5\n",
      "Fit time: 4.965516567230225\n",
      "Metrics:\n",
      "Train set R^2 score:        0.9993189997369007\n",
      "Test set R^2 score:         0.9975089468355831\n",
      "Mean absolute error:        249.39505523454716\n",
      "RMSE on test set:           592.7213202642185\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=-1, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('num', Pipeline(memory=None,\n",
       "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "       verbose=0... fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=11, solver='auto', tol=0.001))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_pipeline(regressor=linear_model.Ridge,\n",
    "               poly_degree=search_cv.best_params_['polynomial features__degree'], \n",
    "               alpha=search_cv.best_params_['regressor__alpha'], \n",
    "#                k_select=search_cv.best_params_['feature select__k'], \n",
    "               random_state=11, \n",
    "               data=pv_dm.sample(200000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for validation\n",
    "def validate_results(model, X_test, y_test, scoring=mse, cv=10, n_jobs=-1, **kwargs):\n",
    "    return cross_val_score(model, X_test, y_test, scoring=mse, cv=cv, n_jobs=n_jobs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 1.313155174255371\n",
      "Degree: 5\n",
      "Metrics:\n",
      "Train set R^2 score:        0.999219039368013\n",
      "Test set R^2 score:         0.9893889531109623\n",
      "Mean absolute error:        295.593234373473\n",
      "RMSE on test set:           1231.1741491129787\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (4, 105312) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 528, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 265, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 230, in _fit\n    **fit_params_steps[name])\n  File \"C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\", line 342, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 614, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 467, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\smouz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\", line 1508, in transform\n    XP[:, i] = X[:, comb].prod(1)\nnumpy.core._exceptions.MemoryError: Unable to allocate array with shape (4, 105312) and data type float64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-f005ff025867>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRidge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8697\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoly_degree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_select\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mcv_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mridge_poly_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-56-d4e98956b4a6>\u001b[0m in \u001b[0;36mvalidate_results\u001b[1;34m(model, X_test, y_test, scoring, cv, n_jobs, **kwargs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# function for validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvalidate_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate array with shape (4, 105312) and data type float64"
     ]
    }
   ],
   "source": [
    "# RIDGE VALIDATION\n",
    "# np.sqrt(mean_squared_error(y_test, y_pred)) \n",
    "     \n",
    "ridge_poly_best = build_pipeline(\n",
    "    regressor=linear_model.Ridge,\n",
    "    poly_degree=search_cv.best_params_['polynomial features__degree'], \n",
    "    alpha=search_cv.best_params_['regressor__alpha'], \n",
    "#     k_select=search_cv.best_params_['feature select__k'], \n",
    "    random_state=11, \n",
    "    data=pv_dm.sample(100000)\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, y_test = build_pipeline(regressor=linear_model.Ridge, alpha=8697, poly_degree=4, k_select=4, split_only=True)\n",
    "cv_results = validate_results(ridge_poly_best, X_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-8c56b74a5275>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RMSE scores:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RMSE mean:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RMSE std:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv_results' is not defined"
     ]
    }
   ],
   "source": [
    "print('RMSE scores:', np.sqrt((cv_results*-1)))\n",
    "print('RMSE mean:', np.mean(np.sqrt((cv_results*-1))))\n",
    "print('RMSE std:', np.std(np.sqrt((cv_results*-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodels API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # manually add intercept term to X_train\n",
    "# X_train = np.append(X_train, np.ones((len(X_train), 1)), axis=1)\n",
    "# # X_test = np.append(X_test, np.ones((len(X_test), 1)), axis=1)\n",
    "\n",
    "# # fit and summarize results\n",
    "# ols = sm.OLS(y_train, X_train)\n",
    "# results = ols.fit()\n",
    "# results.summary()\n",
    "\n",
    "# # print(train_set.drop(columns='cost').columns.values)\n",
    "# # results.summary2()\n",
    "# sns.scatterplot(x=results.resid, y=results.fittedvalues)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot RMSE vs. Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot RMSE vs a single hyperparameter of some estimator\n",
    "\n",
    "def plot_rmse(estimator, value_name, test_values, degree=2, plot=False, **kwargs):\n",
    "    rmse_ls = []\n",
    "    r2_score_ls = []\n",
    "    # Compute scores over range of alphas\n",
    "    for i in test_values:\n",
    "\n",
    "        X_train, y_train, X_test, y_test = build_pipeline(regressor=estimator,\n",
    "                                                          k_select=5,\n",
    "                                                          split_only=True,\n",
    "                                                          data=pv_dm.sample(200000)\n",
    "                                                         )\n",
    "        pipeline = build_pipeline(regressor=estimator,\n",
    "                                  poly_degree=degree,\n",
    "                                  alpha=i,\n",
    "                                  k_select=5,\n",
    "                                  model_only=True,\n",
    "                                  data=pv_dm.sample(200000)\n",
    "                                 )\n",
    "\n",
    "        y_pred = pipeline.fit(X_train, y_train.values.ravel()).predict(X_test)\n",
    "        rmse_ls.append(np.sqrt(mean_squared_error(y_test.values.ravel(), y_pred)))\n",
    "        r2_score_ls.append(r2_score(y_test, y_pred))\n",
    "\n",
    "    df_rmse = pd.DataFrame({'rmse': rmse_ls,\n",
    "                            'test_values': test_values,\n",
    "                            'r2_score': r2_score_ls\n",
    "                           })\n",
    "    if plot:\n",
    "        plt.scatter(x = df_rmse.test_values, y = df_rmse.rmse, alpha=0.5, marker='.')\n",
    "        plt.xscale('log')\n",
    "#         plt.ylim([df_rmse.root_mean.min()-100, df_rmse.root_mean.max()+100])\n",
    "#         plt.xlim([df_rmse.test_values.min(), df_rmse.test_values.max()])\n",
    "        plt.title(f'RMSE for {value_name.capitalize()}\\n{str(estimator)}')\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.show()\n",
    "#     return df_rmse[df_rmse['root_mean'] == df_rmse['root_mean'].min()]['test_values']\n",
    "    return df_rmse.sort_values(by='rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25.        , 25.71428571, 26.42857143, 27.14285714, 27.85714286,\n",
       "       28.57142857, 29.28571429, 30.        ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(25, 30, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ridge Regression Plot\n",
    "# np.logspace(1, 2, 20)\n",
    "alpha_space = np.linspace(25, 30, 8)\n",
    "alpha_df = plot_rmse(\n",
    "    estimator=linear_model.Ridge,\n",
    "    value_name = 'alpha',\n",
    "    test_values = alpha_space,\n",
    "    degree=4,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>test_values</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>445.9045</td>\n",
       "      <td>27.1429</td>\n",
       "      <td>0.9986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>464.7697</td>\n",
       "      <td>29.2857</td>\n",
       "      <td>0.9985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>479.3381</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>0.9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>504.0898</td>\n",
       "      <td>28.5714</td>\n",
       "      <td>0.9982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>526.7068</td>\n",
       "      <td>27.8571</td>\n",
       "      <td>0.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>530.3285</td>\n",
       "      <td>26.4286</td>\n",
       "      <td>0.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>530.9320</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>556.3523</td>\n",
       "      <td>25.7143</td>\n",
       "      <td>0.9978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rmse  test_values  r2_score\n",
       "3 445.9045      27.1429    0.9986\n",
       "6 464.7697      29.2857    0.9985\n",
       "0 479.3381      25.0000    0.9984\n",
       "5 504.0898      28.5714    0.9982\n",
       "4 526.7068      27.8571    0.9981\n",
       "2 530.3285      26.4286    0.9980\n",
       "7 530.9320      30.0000    0.9980\n",
       "1 556.3523      25.7143    0.9978"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ridge regressor\n",
    "# print('alpha value:', alpha.values)\n",
    "# build_model(linear_model.Ridge, alpha=alpha.values)\n",
    "alpha_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression \n",
    "Using Polynomial Features with varying degrees create additional features and evaluate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=None, copy_X=True, cv=5, eps=0.0001, fit_intercept=True,\n",
       "    max_iter=5000, n_alphas=20, n_jobs=None, normalize=True,\n",
       "    positive=False, precompute='auto', random_state=None,\n",
       "    selection='cyclic', tol=0.0001, verbose=False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# list degrees to test\n",
    "degrees = np.arange(1,6)\n",
    "# initialize lists to collect variables\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "ridge = build_pipeline(regressor=linear_model.Ridge, alpha=0.1233, poly_degree=2, k_select=5)\n",
    "\n",
    "# for degree in range(degree_min,degree_max+1):\n",
    "#     <insert pipeline here>\n",
    "\n",
    "#     predicted = model.fit(X_train,y_train).predict(X_test)\n",
    "# #     print('\\n','='*50)\n",
    "#     print('Degree:              ', degree)\n",
    "#     print('RMSE:                ', np.sqrt(mean_squared_error(y_test, predicted)))\n",
    "#     print('Test set R-sq score: ', model.score(X_test, y_test))\n",
    "#     print('\\n','='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['cost_per_watt', 'annual_pv_prod', 'area_est', 'power_density', 'cost_per_area', 'cost_per_kwh']\n",
      "Fit time: 11.347333431243896\n",
      "Metrics:\n",
      "Train set R^2 score:        0.9999956242015687\n",
      "Test set R^2 score:         0.9999583678541525\n",
      "Mean absolute error:        31.75319566260615\n",
      "RMSE on test set:           77.23820372273998\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "rf = build_pipeline(regressor=RandomForestRegressor, n_estimators=30, k_select=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['cost_per_watt', 'annual_pv_prod', 'area_est', 'power_density', 'cost_per_area', 'cost_per_kwh']\n",
      "Fit time: 10.157321214675903\n",
      "Metrics:\n",
      "Train set R^2 score:        0.9999954631229989\n",
      "Test set R^2 score:         0.9999570605734821\n",
      "Mean absolute error:        32.67714469674132\n",
      "RMSE on test set:           78.44149946170401\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "rf = build_pipeline(regressor=RandomForestRegressor, n_estimators=29, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf.named_steps['randomforestregressor'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print how important each column is to the model\n",
    "# for i, item in enumerate(rf.feature_importances_):\n",
    "#       # Use i and item to print out the feature importance of each column\n",
    "#     print(\"{0:s}: {1:.2f}\".format(X_train.columns[i], item))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
